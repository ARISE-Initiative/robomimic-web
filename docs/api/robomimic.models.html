

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>robomimic.models package &mdash; robomimic 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../static/theme_overrides.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
        <script src="../static/jquery.js"></script>
        <script src="../static/underscore.js"></script>
        <script src="../static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="robomimic.utils package" href="robomimic.utils.html" />
    <link rel="prev" title="robomimic.envs package" href="robomimic.envs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> robomimic
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/advanced.html">Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/examples.html">Working with robomimic Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/datasets.html">Using Demonstration Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/model_zoo.html">Using the Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/results.html">Reproducing Study Results</a></li>
</ul>
<p class="caption"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/dataset.html">SequenceDataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/configs.html">Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/environments.html">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/utils.html">Utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Source API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="robomimic.html">robomimic package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="robomimic.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="robomimic.algo.html">robomimic.algo package</a></li>
<li class="toctree-l3"><a class="reference internal" href="robomimic.config.html">robomimic.config package</a></li>
<li class="toctree-l3"><a class="reference internal" href="robomimic.envs.html">robomimic.envs package</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">robomimic.models package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-robomimic.models.base_nets">robomimic.models.base_nets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-robomimic.models.distributions">robomimic.models.distributions module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-robomimic.models.obs_nets">robomimic.models.obs_nets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-robomimic.models.policy_nets">robomimic.models.policy_nets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-robomimic.models.vae_nets">robomimic.models.vae_nets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-robomimic.models.value_nets">robomimic.models.value_nets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-robomimic.models">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="robomimic.utils.html">robomimic.utils package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="robomimic.html#module-robomimic">Module contents</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Miscellaneous</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../miscellaneous/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../miscellaneous/contributing.html">Contributing Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../miscellaneous/team.html">Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../miscellaneous/acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../miscellaneous/references.html">Projects using robomimic</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">robomimic</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="robomimic.html">robomimic package</a> &raquo;</li>
        
      <li>robomimic.models package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../sources/api/robomimic.models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="robomimic-models-package">
<h1>robomimic.models package<a class="headerlink" href="#robomimic-models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-robomimic.models.base_nets">
<span id="robomimic-models-base-nets-module"></span><h2>robomimic.models.base_nets module<a class="headerlink" href="#module-robomimic.models.base_nets" title="Permalink to this headline">¶</a></h2>
<p>Contains torch Modules that correspond to basic network building blocks, like
MLP, RNN, and CNN backbones.</p>
<dl class="py class">
<dt id="robomimic.models.base_nets.ConvBase">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">ConvBase</span></code><a class="headerlink" href="#robomimic.models.base_nets.ConvBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for ConvNets.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.ConvBase.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ConvBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.ConvBase.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ConvBase.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.ConvBase.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.ConvBase.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.CoordConv2d">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">CoordConv2d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coord_encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'position'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv2d</span></code>, <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>2D Coordinate Convolution</p>
<p>Source: An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution
<a class="reference external" href="https://arxiv.org/abs/1807.03247">https://arxiv.org/abs/1807.03247</a>
(e.g. adds 2 channels per input feature map corresponding to (x, y) location on map)</p>
<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.bias">
<code class="sig-name descname"><span class="pre">bias</span></code><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.bias" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.dilation">
<code class="sig-name descname"><span class="pre">dilation</span></code><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">…</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.dilation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.CoordConv2d.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.groups">
<code class="sig-name descname"><span class="pre">groups</span></code><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.groups" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.kernel_size">
<code class="sig-name descname"><span class="pre">kernel_size</span></code><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">…</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.kernel_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.out_channels">
<code class="sig-name descname"><span class="pre">out_channels</span></code><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.out_channels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.output_padding">
<code class="sig-name descname"><span class="pre">output_padding</span></code><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">…</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.output_padding" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.CoordConv2d.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.padding">
<code class="sig-name descname"><span class="pre">padding</span></code><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">…</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.padding" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.padding_mode">
<code class="sig-name descname"><span class="pre">padding_mode</span></code><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.padding_mode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.stride">
<code class="sig-name descname"><span class="pre">stride</span></code><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">…</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.stride" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.transposed">
<code class="sig-name descname"><span class="pre">transposed</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.transposed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CoordConv2d.weight">
<code class="sig-name descname"><span class="pre">weight</span></code><em class="property"><span class="pre">:</span> <span class="pre">torch.Tensor</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.weight" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.CropRandomizer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">CropRandomizer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_height</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_crops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_enc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CropRandomizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Randomizer" title="robomimic.models.base_nets.Randomizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Randomizer</span></code></a></p>
<p>Randomly sample crops at input, and then average across crop features at output.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.CropRandomizer.forward_in">
<code class="sig-name descname"><span class="pre">forward_in</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CropRandomizer.forward_in" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples N random crops for each input in the batch, and then reshapes
inputs to [B * N, …].</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.CropRandomizer.forward_out">
<code class="sig-name descname"><span class="pre">forward_out</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CropRandomizer.forward_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the outputs from shape [B * N, …] -&gt; [B, N, …] and then average across N
to result in shape [B, …] to make sure the network output is consistent with
what would have happened if there were no randomization.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.CropRandomizer.output_shape_in">
<code class="sig-name descname"><span class="pre">output_shape_in</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CropRandomizer.output_shape_in" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_in operation, where raw inputs (usually observation modalities)
are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.CropRandomizer.output_shape_out">
<code class="sig-name descname"><span class="pre">output_shape_out</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CropRandomizer.output_shape_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_out operation, where processed inputs (usually encoded observation
modalities) are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.CropRandomizer.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.CropRandomizer.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.FeatureAggregator">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">FeatureAggregator</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">agg_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'avg'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Helpful class for aggregating features across a dimension. This is useful in
practice when training models that break an input image up into several patches
since features can be extraced per-patch using the same encoder and then
aggregated using this module.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.FeatureAggregator.clear_weight">
<code class="sig-name descname"><span class="pre">clear_weight</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.clear_weight" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.FeatureAggregator.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pooling pass.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.FeatureAggregator.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.FeatureAggregator.set_weight">
<code class="sig-name descname"><span class="pre">set_weight</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.set_weight" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.FeatureAggregator.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.MLP">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">MLP</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_dim</span></em>, <em class="sig-param"><span class="pre">output_dim</span></em>, <em class="sig-param"><span class="pre">layer_dims=()</span></em>, <em class="sig-param"><span class="pre">layer_func=&lt;class</span> <span class="pre">'torch.nn.modules.linear.Linear'&gt;</span></em>, <em class="sig-param"><span class="pre">layer_func_kwargs=None</span></em>, <em class="sig-param"><span class="pre">activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></em>, <em class="sig-param"><span class="pre">dropouts=None</span></em>, <em class="sig-param"><span class="pre">normalization=False</span></em>, <em class="sig-param"><span class="pre">output_activation=None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for simple Multi-Layer Perceptrons.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.MLP.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MLP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.MLP.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MLP.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.MLP.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.MLP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.Module">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">Module</span></code><a class="headerlink" href="#robomimic.models.base_nets.Module" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Base class for networks. The only difference from torch.nn.Module is that it
requires implementing &#64;output_shape.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.Module.output_shape">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Module.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.Module.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Module.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.Parameter">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">Parameter</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A class that is a thin wrapper around a torch.nn.Parameter to make for easy saving
and optimization.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.Parameter.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Parameter.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward call just returns the parameter tensor.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.Parameter.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Parameter.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.Parameter.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Parameter.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.RNN_Base">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">RNN_Base</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LSTM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_step_net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A wrapper class for a multi-step RNN and a per-step network.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.RNN_Base.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward a sequence of inputs through the RNN and the per-step network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.Tensor</em>) – tensor input of shape [B, T, D], where D is the RNN input size</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>outputs of the per_step_net</p>
<p>rnn_state: return rnn state at the end if return_state is set to True</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>outputs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.RNN_Base.forward_step">
<code class="sig-name descname"><span class="pre">forward_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward a single step input through the RNN and per-step network, and return the new hidden state.
:param inputs: tensor input of shape [B, D], where D is the RNN input size
:type inputs: torch.Tensor
:param rnn_state: rnn hidden state, initialize to zero state if set to None</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>outputs of the per_step_net</p>
<p>rnn_state: return the new rnn state</p>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>outputs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.RNN_Base.get_rnn_init_state">
<code class="sig-name descname"><span class="pre">get_rnn_init_state</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.get_rnn_init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a default RNN state (zeros)
:param batch_size: batch size dimension
:type batch_size: int
:param device: device the hidden state should be sent to.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>returns hidden state tensor or tuple of hidden state tensors</dt><dd><p>depending on the RNN type</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>hidden_state (torch.Tensor or tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.RNN_Base.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.RNN_Base.rnn_type">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">rnn_type</span></code><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.rnn_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.RNN_Base.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.Randomizer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">Randomizer</span></code><a class="headerlink" href="#robomimic.models.base_nets.Randomizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for randomizer networks. Each randomizer should implement the &#64;output_shape_in,
&#64;output_shape_out, &#64;forward_in, and &#64;forward_out methods. The randomizer’s &#64;forward_in
method is invoked on raw inputs, and &#64;forward_out is invoked on processed inputs
(usually processed by a &#64;VisualCore instance). Note that the self.training property
can be used to change the randomizer’s behavior at train vs. test time.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.Randomizer.forward_in">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">forward_in</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Randomizer.forward_in" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomize raw inputs.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.Randomizer.forward_out">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">forward_out</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Randomizer.forward_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Processing for network outputs.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.Randomizer.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Randomizer.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is unused. See &#64;output_shape_in and &#64;output_shape_out.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.Randomizer.output_shape_in">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">output_shape_in</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Randomizer.output_shape_in" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_in operation, where raw inputs (usually observation modalities)
are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.Randomizer.output_shape_out">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">output_shape_out</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Randomizer.output_shape_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_out operation, where processed inputs (usually encoded observation
modalities) are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.Randomizer.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Randomizer.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.ResNet18Conv">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">ResNet18Conv</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_coord_conv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ResNet18Conv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>A ResNet18 block that can be used to process input images.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.ResNet18Conv.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ResNet18Conv.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.ResNet18Conv.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.ResNet18Conv.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.Sequential">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">Sequential</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Sequential" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.Sequential</span></code>, <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Compose multiple Modules together (defined above).</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.Sequential.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Sequential.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.Sequential.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Sequential.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.ShallowConv">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">ShallowConv</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ShallowConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>A shallow convolutional encoder from <a class="reference external" href="https://rll.berkeley.edu/dsae/dsae.pdf">https://rll.berkeley.edu/dsae/dsae.pdf</a></p>
<dl class="py method">
<dt id="robomimic.models.base_nets.ShallowConv.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ShallowConv.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.ShallowConv.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.ShallowConv.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.SpatialMeanPool">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">SpatialMeanPool</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Module that averages inputs across all spatial dimensions (dimension 2 and after),
leaving only the batch and channel dimensions.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.SpatialMeanPool.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass - average across all dimensions except batch and channel.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.SpatialMeanPool.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.SpatialMeanPool.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.SpatialSoftmax">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">SpatialSoftmax</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_kp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learnable_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>Spatial Softmax Layer.</p>
<p>Based on Deep Spatial Autoencoders for Visuomotor Learning by Finn et al.
<a class="reference external" href="https://rll.berkeley.edu/dsae/dsae.pdf">https://rll.berkeley.edu/dsae/dsae.pdf</a></p>
<dl class="py method">
<dt id="robomimic.models.base_nets.SpatialSoftmax.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass through spatial softmax layer. For each keypoint, a 2D spatial
probability distribution is created using a softmax, where the support is the
pixel locations. This distribution is used to compute the expected value of
the pixel location, which becomes a keypoint of dimension 2. K such keypoints
are created.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>mean keypoints of shape [B, K, 2], and possibly</dt><dd><p>keypoint variance of shape [B, K, 2, 2] corresponding to the covariance
under the 2D spatial softmax distribution</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>out (torch.Tensor or tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.SpatialSoftmax.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.SpatialSoftmax.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.base_nets.VisualCore">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">VisualCore</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flatten</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.VisualCore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>A network block that combines a visual backbone network with optional pooling
and linear layers.</p>
<dl class="py method">
<dt id="robomimic.models.base_nets.VisualCore.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.VisualCore.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass through visual core.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.base_nets.VisualCore.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.VisualCore.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.base_nets.VisualCore.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.VisualCore.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="robomimic.models.base_nets.rnn_args_from_config">
<code class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></code><code class="sig-name descname"><span class="pre">rnn_args_from_config</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.rnn_args_from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a Config object corresponding to RNN settings
(for example <cite>config.algo.rnn</cite> in BCConfig) and extracts
rnn kwargs for instantiating rnn networks.</p>
</dd></dl>

</div>
<div class="section" id="module-robomimic.models.distributions">
<span id="robomimic-models-distributions-module"></span><h2>robomimic.models.distributions module<a class="headerlink" href="#module-robomimic.models.distributions" title="Permalink to this headline">¶</a></h2>
<p>Contains distribution models used as parts of other networks. These
classes usually inherit or emulate torch distributions.</p>
<dl class="py class">
<dt id="robomimic.models.distributions.DiscreteValueDistribution">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.distributions.</span></code><code class="sig-name descname"><span class="pre">DiscreteValueDistribution</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Extension to torch categorical probability distribution in order to keep track
of the support (categorical values, or in this case, value atoms). This is
used for distributional value networks.</p>
<dl class="py method">
<dt id="robomimic.models.distributions.DiscreteValueDistribution.logits">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">logits</span></code><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.DiscreteValueDistribution.mean">
<code class="sig-name descname"><span class="pre">mean</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Categorical distribution mean, taking the value support into account.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.DiscreteValueDistribution.probs">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">probs</span></code><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.DiscreteValueDistribution.sample">
<code class="sig-name descname"><span class="pre">sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample from the distribution. Make sure to return value atoms, not categorical class indices.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.DiscreteValueDistribution.values">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">values</span></code><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.values" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.DiscreteValueDistribution.variance">
<code class="sig-name descname"><span class="pre">variance</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.variance" title="Permalink to this definition">¶</a></dt>
<dd><p>Categorical distribution variance, taking the value support into account.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.distributions.TanhWrappedDistribution">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.distributions.</span></code><code class="sig-name descname"><span class="pre">TanhWrappedDistribution</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></p>
<p>Class that wraps another valid torch distribution, such that sampled values from the base distribution are
passed through a tanh layer. The corresponding (log) probabilities are also modified accordingly.
Tanh Normal distribution - adapted from rlkit and CQL codebase
(<a class="reference external" href="https://github.com/aviralkumar2907/CQL/blob/d67dbe9cf5d2b96e3b462b6146f249b3d6569796/d4rl/rlkit/torch/distributions.py#L6">https://github.com/aviralkumar2907/CQL/blob/d67dbe9cf5d2b96e3b462b6146f249b3d6569796/d4rl/rlkit/torch/distributions.py#L6</a>).</p>
<dl class="py method">
<dt id="robomimic.models.distributions.TanhWrappedDistribution.log_prob">
<code class="sig-name descname"><span class="pre">log_prob</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_tanh_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – some tensor to compute log probabilities for</p></li>
<li><p><strong>pre_tanh_value</strong> – If specified, will not calculate atanh manually from &#64;value. More numerically stable</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.TanhWrappedDistribution.mean">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">mean</span></code><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mean of the distribution.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.TanhWrappedDistribution.rsample">
<code class="sig-name descname"><span class="pre">rsample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_pretanh_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.rsample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sampling in the reparameterization case - for differentiable samples.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.TanhWrappedDistribution.sample">
<code class="sig-name descname"><span class="pre">sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_pretanh_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradients will and should <em>not</em> pass through this operation.
See <a class="reference external" href="https://github.com/pytorch/pytorch/issues/4620">https://github.com/pytorch/pytorch/issues/4620</a> for discussion.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.distributions.TanhWrappedDistribution.stddev">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">stddev</span></code><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.stddev" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the standard deviation of the distribution.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-robomimic.models.obs_nets">
<span id="robomimic-models-obs-nets-module"></span><h2>robomimic.models.obs_nets module<a class="headerlink" href="#module-robomimic.models.obs_nets" title="Permalink to this headline">¶</a></h2>
<p>Contains torch Modules that help deal with inputs consisting of multiple
modalities. This is extremely common when networks must deal with one or
more observation dictionaries, where each input dictionary can have
modality keys of a certain type and shape.</p>
<p>As an example, an observation could consist of a flat “robot0_eef_pos” modality,
and a 3-channel RGB “agentview_image” modality.</p>
<dl class="py class">
<dt id="robomimic.models.obs_nets.MIMO_MLP">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></code><code class="sig-name descname"><span class="pre">MIMO_MLP</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_obs_group_shapes</span></em>, <em class="sig-param"><span class="pre">output_shapes</span></em>, <em class="sig-param"><span class="pre">layer_dims</span></em>, <em class="sig-param"><span class="pre">layer_func=&lt;class</span> <span class="pre">'torch.nn.modules.linear.Linear'&gt;</span></em>, <em class="sig-param"><span class="pre">activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></em>, <em class="sig-param"><span class="pre">visual_feature_dimension=64</span></em>, <em class="sig-param"><span class="pre">visual_core_class='ResNet18Conv'</span></em>, <em class="sig-param"><span class="pre">visual_core_kwargs=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_class=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_kwargs=None</span></em>, <em class="sig-param"><span class="pre">use_spatial_softmax=False</span></em>, <em class="sig-param"><span class="pre">spatial_softmax_kwargs=None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Extension to MLP to accept multiple observation dictionaries as input and
to output dictionaries of tensors. Inputs are specified as a dictionary of
observation dictionaries, with each key corresponding to an observation group.</p>
<p>This module utilizes &#64;ObservationGroupEncoder to process the multiple input dictionaries and
&#64;ObservationDecoder to generate tensor dictionaries. The default behavior
for encoding the inputs is to process visual inputs with a learned CNN and concatenating
the flat encodings with the other flat inputs. The default behavior for generating
outputs is to use a linear layer branch to produce each modality separately
(including visual outputs).</p>
<dl class="py method">
<dt id="robomimic.models.obs_nets.MIMO_MLP.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Process each set of inputs in its own observation group.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>dict</em>) – a dictionary of dictionaries with one dictionary per
observation group. Each observation group’s dictionary should map
modality to torch.Tensor batches. Should be consistent with
&#64;self.input_obs_group_shapes.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.MIMO_MLP.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.obs_nets.MIMO_MLP.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.obs_nets.ObservationDecoder">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></code><code class="sig-name descname"><span class="pre">ObservationDecoder</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decode_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_feat_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Module that can generate observation outputs by modality. Inputs are assumed
to be flat (usually outputs from some hidden layer). Each observation output
is generated with a linear layer from these flat inputs. Subclass this
module in order to implement more complex schemes for generating each
modality.</p>
<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationDecoder.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feats</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict each modality from input features, and reshape to each modality’s shape.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationDecoder.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.obs_nets.ObservationDecoder.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.obs_nets.ObservationEncoder">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></code><code class="sig-name descname"><span class="pre">ObservationEncoder</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">feature_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Module that processes inputs by modality and then concatenates the processed
modalities together. Each modality is processed with an encoder head network.
Call &#64;register_modality to register modalities with the encoder and then
finally call &#64;make to create the encoder networks.</p>
<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationEncoder.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Processes modalities according to the ordering in &#64;self.obs_shapes. For each
modality, it is processed with a randomizer (if present), an encoder
network (if present), and again with the randomizer (if present), flattened,
and then concatenated with the other processed modalities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obs_dict</strong> (<em>OrderedDict</em>) – dictionary that maps modalities to torch.Tensor
batches that agree with &#64;self.obs_shapes. All modalities in
&#64;self.obs_shapes must be present, but additional modalities
can also be present.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>flat features of shape [B, D]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>feats (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationEncoder.make">
<code class="sig-name descname"><span class="pre">make</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.make" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the encoder networks and locks the encoder so that more modalities cannot be added.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationEncoder.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output shape of the encoder.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationEncoder.register_modality">
<code class="sig-name descname"><span class="pre">register_modality</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mod_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mod_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mod_net_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mod_net_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mod_net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mod_randomizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_mod_net_from</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.register_modality" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a modality that this encoder should be responsible for.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mod_name</strong> (<em>str</em>) – modality name</p></li>
<li><p><strong>mod_shape</strong> (<em>int tuple</em>) – shape of modality</p></li>
<li><p><strong>mod_net_class</strong> (<em>str</em>) – name of class in base_nets.py that should be used
to process this modality before concatenation. Pass None to flatten
and concatenate the modality directly.</p></li>
<li><p><strong>mod_net_kwargs</strong> (<em>dict</em>) – arguments to pass to &#64;mod_net_class</p></li>
<li><p><strong>mod_net</strong> (<em>Module instance</em>) – if provided, use this Module to process the modality
instead of creating a different net</p></li>
<li><p><strong>mod_randomizer</strong> (<em>Randomizer instance</em>) – if provided, use this Module to augment modalities
coming in to the encoder, and possibly augment the processed output as well</p></li>
<li><p><strong>share_mod_net_from</strong> (<em>str</em>) – if provided, use the same instance of &#64;mod_net_class
as another modality. This modality must already exist in this encoder.
Warning: Note that this does not share the modality randomizer</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.obs_nets.ObservationEncoder.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.obs_nets.ObservationGroupEncoder">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></code><code class="sig-name descname"><span class="pre">ObservationGroupEncoder</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">observation_group_shapes</span></em>, <em class="sig-param"><span class="pre">visual_feature_dimension=64</span></em>, <em class="sig-param"><span class="pre">visual_core_class='ResNet18Conv'</span></em>, <em class="sig-param"><span class="pre">visual_core_kwargs=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_class=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_kwargs=None</span></em>, <em class="sig-param"><span class="pre">use_spatial_softmax=True</span></em>, <em class="sig-param"><span class="pre">spatial_softmax_kwargs=None</span></em>, <em class="sig-param"><span class="pre">feature_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>This class allows networks to encode multiple observation dictionaries into a single
flat, concatenated vector representation. It does this by assigning each observation
dictionary (observation group) an &#64;ObservationEncoder object.</p>
<p>The class takes a dictionary of dictionaries, &#64;observation_group_shapes.
Each key corresponds to a observation group (e.g. ‘obs’, ‘subgoal’, ‘goal’)
and each OrderedDict should be a map between modalities and
expected input shapes (e.g. { ‘image’ : (3, 120, 160) }).</p>
<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationGroupEncoder.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Process each set of inputs in its own observation group.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>dict</em>) – dictionary that maps observation groups to observation
dictionaries of torch.Tensor batches that agree with
&#64;self.observation_group_shapes. All observation groups in
&#64;self.observation_group_shapes must be present, but additional
observation groups can also be present. Note that these are specified
as kwargs for ease of use with networks that name each observation
stream in their forward calls.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>flat outputs of shape [B, D]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>outputs (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.ObservationGroupEncoder.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output shape of this encoder.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.obs_nets.ObservationGroupEncoder.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.obs_nets.RNN_MIMO_MLP">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></code><code class="sig-name descname"><span class="pre">RNN_MIMO_MLP</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_obs_group_shapes</span></em>, <em class="sig-param"><span class="pre">output_shapes</span></em>, <em class="sig-param"><span class="pre">mlp_layer_dims</span></em>, <em class="sig-param"><span class="pre">rnn_hidden_dim</span></em>, <em class="sig-param"><span class="pre">rnn_num_layers</span></em>, <em class="sig-param"><span class="pre">rnn_type='LSTM'</span></em>, <em class="sig-param"><span class="pre">rnn_kwargs=None</span></em>, <em class="sig-param"><span class="pre">mlp_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></em>, <em class="sig-param"><span class="pre">mlp_layer_func=&lt;class</span> <span class="pre">'torch.nn.modules.linear.Linear'&gt;</span></em>, <em class="sig-param"><span class="pre">per_step=True</span></em>, <em class="sig-param"><span class="pre">visual_feature_dimension=64</span></em>, <em class="sig-param"><span class="pre">visual_core_class='ResNet18Conv'</span></em>, <em class="sig-param"><span class="pre">visual_core_kwargs=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_class=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_kwargs=None</span></em>, <em class="sig-param"><span class="pre">use_spatial_softmax=False</span></em>, <em class="sig-param"><span class="pre">spatial_softmax_kwargs=None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A wrapper class for a multi-step RNN and a per-step MLP and a decoder.</p>
<p>Structure: [encoder -&gt; rnn -&gt; mlp -&gt; decoder]</p>
<p>All temporal inputs are processed by a shared &#64;ObservationGroupEncoder,
followed by an RNN, and then a per-step multi-output MLP.</p>
<dl class="py method">
<dt id="robomimic.models.obs_nets.RNN_MIMO_MLP.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – a dictionary of dictionaries with one dictionary per
observation group. Each observation group’s dictionary should map
modality to torch.Tensor batches. Should be consistent with
&#64;self.input_obs_group_shapes. First two leading dimensions should
be batch and time [B, T, …] for each tensor.</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes. Leading dimensions will be batch and time [B, T, …]
for each tensor.</p>
</dd>
</dl>
<p>rnn_state (torch.Tensor or tuple): return the new rnn state (if &#64;return_state)</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.RNN_MIMO_MLP.forward_step">
<code class="sig-name descname"><span class="pre">forward_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Unroll network over a single timestep.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – expects same modalities as &#64;self.input_shapes, with
additional batch dimension (but NOT time), since this is a
single time step.</p></li>
<li><p><strong>rnn_state</strong> (<em>torch.Tensor</em>) – rnn hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes. Does not contain time dimension.</p>
</dd>
</dl>
<p>rnn_state: return the new rnn state</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.RNN_MIMO_MLP.get_rnn_init_state">
<code class="sig-name descname"><span class="pre">get_rnn_init_state</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.get_rnn_init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a default RNN state (zeros)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size dimension</p></li>
<li><p><strong>device</strong> – device the hidden state should be sent to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>returns hidden state tensor or tuple of hidden state tensors</dt><dd><p>depending on the RNN type</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>hidden_state (torch.Tensor or tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.obs_nets.RNN_MIMO_MLP.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>dict</em>) – dictionary of dictionaries, where each top-level key
corresponds to an observation group, and the low-level dictionaries
specify the shape for each modality in an observation dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.obs_nets.RNN_MIMO_MLP.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="robomimic.models.obs_nets.obs_encoder_args_from_config">
<code class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></code><code class="sig-name descname"><span class="pre">obs_encoder_args_from_config</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_encoder_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.obs_encoder_args_from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of args used to create visual backbones for networks
from the obseration encoder config.</p>
</dd></dl>

<dl class="py function">
<dt id="robomimic.models.obs_nets.obs_encoder_factory">
<code class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></code><code class="sig-name descname"><span class="pre">obs_encoder_factory</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">obs_shapes</span></em>, <em class="sig-param"><span class="pre">visual_feature_dimension</span></em>, <em class="sig-param"><span class="pre">visual_core_class</span></em>, <em class="sig-param"><span class="pre">visual_core_kwargs=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_class=None</span></em>, <em class="sig-param"><span class="pre">obs_randomizer_kwargs=None</span></em>, <em class="sig-param"><span class="pre">use_spatial_softmax=False</span></em>, <em class="sig-param"><span class="pre">spatial_softmax_kwargs=None</span></em>, <em class="sig-param"><span class="pre">feature_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.obs_encoder_factory" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility function to create an &#64;ObservationEncoder from kwargs specified in config.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_shapes</strong> (<em>OrderedDict</em>) – a dictionary that maps modality to
expected shapes for observations.</p></li>
<li><p><strong>visual_feature_dimension</strong> (<em>int</em>) – feature dimension to encode images into</p></li>
<li><p><strong>visual_core_class</strong> (<em>str</em>) – specifies Visual Backbone network for encoding images</p></li>
<li><p><strong>visual_core_kwargs</strong> (<em>dict</em>) – arguments to pass to &#64;visual_core_class</p></li>
<li><p><strong>obs_randomizer_class</strong> (<em>str</em>) – specifies a Randomizer class for the input modality</p></li>
<li><p><strong>obs_randomizer_kwargs</strong> (<em>dict</em>) – kwargs for the observation randomizer</p></li>
<li><p><strong>use_spatial_softmax</strong> (<em>bool</em>) – if True, introduce a spatial softmax layer at
the end of the visual backbone network, resulting in a sharp bottleneck
representation for visual inputs.</p></li>
<li><p><strong>spatial_softmax_kwargs</strong> (<em>dict</em>) – arguments to pass to spatial softmax layer</p></li>
<li><p><strong>feature_activation</strong> – non-linearity to apply after each obs net - defaults to ReLU. Pass
None to apply no activation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-robomimic.models.policy_nets">
<span id="robomimic-models-policy-nets-module"></span><h2>robomimic.models.policy_nets module<a class="headerlink" href="#module-robomimic.models.policy_nets" title="Permalink to this headline">¶</a></h2>
<p>Contains torch Modules for policy networks. These networks take an
observation dictionary as input (and possibly additional conditioning,
such as subgoal or goal dictionaries) and produce action predictions,
samples, or distributions as outputs. Note that actions
are assumed to lie in [-1, 1], and most networks will have a final
tanh activation to help ensure this range.</p>
<dl class="py class">
<dt id="robomimic.models.policy_nets.ActorNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></code><code class="sig-name descname"><span class="pre">ActorNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_nets.MIMO_MLP" title="robomimic.models.obs_nets.MIMO_MLP"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_nets.MIMO_MLP</span></code></a></p>
<p>A basic policy network that predicts actions from observations.
Can optionally be goal conditioned on future observations.</p>
<dl class="py method">
<dt id="robomimic.models.policy_nets.ActorNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Process each set of inputs in its own observation group.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>dict</em>) – a dictionary of dictionaries with one dictionary per
observation group. Each observation group’s dictionary should map
modality to torch.Tensor batches. Should be consistent with
&#64;self.input_obs_group_shapes.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.ActorNetwork.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.policy_nets.ActorNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.policy_nets.GMMActorNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></code><code class="sig-name descname"><span class="pre">GMMActorNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softplus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tanh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.ActorNetwork" title="robomimic.models.policy_nets.ActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.ActorNetwork</span></code></a></p>
<p>Variant of actor network that learns a multimodal Gaussian mixture distribution
over actions.</p>
<dl class="py method">
<dt id="robomimic.models.policy_nets.GMMActorNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.GMMActorNetwork.forward_train">
<code class="sig-name descname"><span class="pre">forward_train</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Return full GMM distribution, which is useful for computing
quantities necessary at train-time, like log-likelihood, KL
divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>GMM distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dist (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.policy_nets.GMMActorNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.policy_nets.GaussianActorNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></code><code class="sig-name descname"><span class="pre">GaussianActorNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softplus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_last_fc_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_limits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-</span> <span class="pre">9.0,</span> <span class="pre">9.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_limits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.007,</span> <span class="pre">7.5)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tanh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.ActorNetwork" title="robomimic.models.policy_nets.ActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.ActorNetwork</span></code></a></p>
<p>Variant of actor network that learns a diagonal unimodal Gaussian distribution
over actions.</p>
<dl class="py method">
<dt id="robomimic.models.policy_nets.GaussianActorNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.GaussianActorNetwork.forward_train">
<code class="sig-name descname"><span class="pre">forward_train</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Return full Gaussian distribution, which is useful for computing
quantities necessary at train-time, like log-likelihood, KL
divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Gaussian distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dist (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.policy_nets.GaussianActorNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.policy_nets.PerturbationActorNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></code><code class="sig-name descname"><span class="pre">PerturbationActorNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbation_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.PerturbationActorNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.ActorNetwork" title="robomimic.models.policy_nets.ActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.ActorNetwork</span></code></a></p>
<p>An action perturbation network - primarily used in BCQ.
It takes states and actions and returns action perturbations.</p>
<dl class="py method">
<dt id="robomimic.models.policy_nets.PerturbationActorNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.PerturbationActorNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass through perturbation actor.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.policy_nets.PerturbationActorNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.PerturbationActorNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.policy_nets.RNNActorNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></code><code class="sig-name descname"><span class="pre">RNNActorNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LSTM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_nets.RNN_MIMO_MLP" title="robomimic.models.obs_nets.RNN_MIMO_MLP"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_nets.RNN_MIMO_MLP</span></code></a></p>
<p>An RNN policy network that predicts actions from observations.</p>
<dl class="py method">
<dt id="robomimic.models.policy_nets.RNNActorNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward a sequence of inputs through the RNN and the per-step network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations - each tensor in the dictionary
should have leading dimensions batch and time [B, T, …]</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>predicted action sequence
rnn_state: return rnn state at the end if return_state is set to True</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>actions (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.RNNActorNetwork.forward_step">
<code class="sig-name descname"><span class="pre">forward_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Unroll RNN over single timestep to get actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations. Should not contain
time dimension.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of actions - does not contain time dimension
state: updated rnn state</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>actions (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.RNNActorNetwork.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>dict</em>) – dictionary of dictionaries, where each top-level key
corresponds to an observation group, and the low-level dictionaries
specify the shape for each modality in an observation dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.policy_nets.RNNActorNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.policy_nets.RNNGMMActorNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></code><code class="sig-name descname"><span class="pre">RNNGMMActorNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LSTM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softplus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tanh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.RNNActorNetwork" title="robomimic.models.policy_nets.RNNActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.RNNActorNetwork</span></code></a></p>
<p>An RNN GMM policy network that predicts sequences of action distributions from observation sequences.</p>
<dl class="py method">
<dt id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward_step">
<code class="sig-name descname"><span class="pre">forward_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Unroll RNN over single timestep to get sampled actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations. Should not contain
time dimension.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of actions - does not contain time dimension
state: updated rnn state</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>acts (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train">
<code class="sig-name descname"><span class="pre">forward_train</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Return full GMM distribution, which is useful for computing
quantities necessary at train-time, like log-likelihood, KL
divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>sequence of GMM distributions over the timesteps
rnn_state: return rnn state at the end if return_state is set to True</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dists (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train_step">
<code class="sig-name descname"><span class="pre">forward_train_step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Unroll RNN over single timestep to get action GMM distribution, which
is useful for computing quantities necessary at train-time, like
log-likelihood, KL divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations. Should not contain
time dimension.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>GMM action distributions
state: updated rnn state</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ad (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.policy_nets.RNNGMMActorNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.policy_nets.VAEActor">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></code><code class="sig-name descname"><span class="pre">VAEActor</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_reconstruction_sum_across_elements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_learn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_gmm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_learn_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_gumbel_softmax_hard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A VAE that models a distribution of actions conditioned on observations.
The VAE prior and decoder are used at test-time as the policy.</p>
<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.decode">
<code class="sig-name descname"><span class="pre">decode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Thin wrapper around &#64;VaeNets.VAE implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. Only needs to be provided if &#64;decoder_is_conditioned
or &#64;z is None (since the prior will require it to generate z).</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – if provided, these latents are used to generate
reconstructions from the VAE, and the prior is not sampled.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number of samples to
generate from the prior. Only required if &#64;z is None - i.e.
sampling takes place</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of reconstructed inputs (this will be a dictionary</dt><dd><p>with a single “action” key)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>recons (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.encode">
<code class="sig-name descname"><span class="pre">encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.encode" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> (<em>torch.Tensor</em>) – a batch of actions</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the observation modalities
used for conditioning in either the decoder or the prior (or both).</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>dictionary with the following keys:</p>
<blockquote>
<div><p>mean (torch.Tensor): posterior encoder means</p>
<p>logvar (torch.Tensor): posterior encoder logvars</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>posterior params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – if not None, use the provided batch of latents instead
of sampling from the prior</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.forward_train">
<code class="sig-name descname"><span class="pre">forward_train</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>A full pass through the VAE network used during training to construct KL
and reconstruction losses. See &#64;VAE class for more info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> (<em>torch.Tensor</em>) – a batch of actions</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the observation modalities
used for conditioning in either the decoder or the prior (or both).</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>a dictionary that contains the following outputs.</p>
<blockquote>
<div><dl class="simple">
<dt>encoder_params (dict): parameters for the posterior distribution</dt><dd><p>from the encoder forward pass</p>
</dd>
</dl>
<p>encoder_z (torch.Tensor): latents sampled from the encoder posterior</p>
<p>decoder_outputs (dict): action reconstructions from the decoder</p>
<p>kl_loss (torch.Tensor): KL loss over the batch of data</p>
<p>reconstruction_loss (torch.Tensor): reconstruction loss over the batch of data</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>vae_outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.get_gumbel_temperature">
<code class="sig-name descname"><span class="pre">get_gumbel_temperature</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.get_gumbel_temperature" title="Permalink to this definition">¶</a></dt>
<dd><p>Return current Gumbel-Softmax temperature. Should only be used if
&#64;prior_use_categorical is True.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>This implementation is required by the Module superclass, but is unused since we
never chain this module to other ones.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.sample_prior">
<code class="sig-name descname"><span class="pre">sample_prior</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.sample_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Thin wrapper around &#64;VaeNets.VAE implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. Only needs to be provided if &#64;prior_is_conditioned.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>latents sampled from the prior</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.policy_nets.VAEActor.set_gumbel_temperature">
<code class="sig-name descname"><span class="pre">set_gumbel_temperature</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">temperature</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.set_gumbel_temperature" title="Permalink to this definition">¶</a></dt>
<dd><p>Used by external algorithms to schedule Gumbel-Softmax temperature,
which is used during reparametrization at train-time. Should only be
used if &#64;prior_use_categorical is True.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.policy_nets.VAEActor.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-robomimic.models.vae_nets">
<span id="robomimic-models-vae-nets-module"></span><h2>robomimic.models.vae_nets module<a class="headerlink" href="#module-robomimic.models.vae_nets" title="Permalink to this headline">¶</a></h2>
<p>Contains an implementation of Variational Autoencoder (VAE) and other
variants, including other priors, and RNN-VAEs.</p>
<dl class="py class">
<dt id="robomimic.models.vae_nets.CategoricalPrior">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></code><code class="sig-name descname"><span class="pre">CategoricalPrior</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learnable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.vae_nets.Prior" title="robomimic.models.vae_nets.Prior"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.vae_nets.Prior</span></code></a></p>
<p>A class that holds functionality for learning categorical priors for use
in VAEs.</p>
<dl class="py method">
<dt id="robomimic.models.vae_nets.CategoricalPrior.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes prior logits (unnormalized log-probs).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size - this is needed for parameters that are
not obs-dependent, to make sure the leading dimension is correct
for downstream sampling and loss computation purposes</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary containing prior parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prior_params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.CategoricalPrior.kl_loss">
<code class="sig-name descname"><span class="pre">kl_loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.kl_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes KL divergence loss between the Categorical distribution
given by the unnormalized logits &#64;logits and the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with key “logits” corresponding
to torch.Tensor batch of unnormalized logits of shape [B, D * C]
that corresponds to the posterior categorical distribution</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – samples from encoder - unused for this prior</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>KL divergence loss</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.CategoricalPrior.sample">
<code class="sig-name descname"><span class="pre">sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a batch of samples from the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent. Leading dimension should
be consistent with &#64;n, the number of samples to generate.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of sampled latent vectors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.vae_nets.CategoricalPrior.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.vae_nets.GaussianPrior">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></code><code class="sig-name descname"><span class="pre">GaussianPrior</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learnable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gmm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gmm_num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gmm_learn_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.vae_nets.Prior" title="robomimic.models.vae_nets.Prior"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.vae_nets.Prior</span></code></a></p>
<p>A class that holds functionality for learning both unimodal Gaussian priors and
multimodal Gaussian Mixture Model priors for use in VAEs.</p>
<dl class="py method">
<dt id="robomimic.models.vae_nets.GaussianPrior.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes means, logvars, and GMM weights (if using GMM and learning weights).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size - this is needed for parameters that are
not obs-dependent, to make sure the leading dimension is correct
for downstream sampling and loss computation purposes</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary containing prior parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prior_params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.GaussianPrior.kl_loss">
<code class="sig-name descname"><span class="pre">kl_loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.kl_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes sample-based KL divergence loss between the Gaussian distribution
given by &#64;mu, &#64;logvar and the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with keys “mu” and “logvar” corresponding
to torch.Tensor batch of means and log-variances of posterior Gaussian
distribution.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – samples from the Gaussian distribution parametrized by
&#64;mu and &#64;logvar. Only needed if &#64;self.use_gmm is True.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>KL divergence loss</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.GaussianPrior.sample">
<code class="sig-name descname"><span class="pre">sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a batch of samples from the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent. Leading dimension should
be consistent with &#64;n, the number of samples to generate.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of sampled latent vectors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.vae_nets.GaussianPrior.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.vae_nets.Prior">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></code><code class="sig-name descname"><span class="pre">Prior</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_obs_dependent</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for VAE priors. It’s basically the same as a &#64;MIMO_MLP network (it
instantiates one) but it supports additional methods such as KL loss computation
and sampling, and also may learn prior parameters as observation-independent
torch Parameters instead of observation-dependent mappings.</p>
<dl class="py method">
<dt id="robomimic.models.vae_nets.Prior.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes prior parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size - this is needed for parameters that are
not obs-dependent, to make sure the leading dimension is correct
for downstream sampling and loss computation purposes</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary containing prior parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prior_params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.Prior.kl_loss">
<code class="sig-name descname"><span class="pre">kl_loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.kl_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes sample-based KL divergence loss between the Gaussian distribution
given by &#64;mu, &#64;logvar and the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with keys “mu” and “logvar” corresponding
to torch.Tensor batch of means and log-variances of posterior Gaussian
distribution.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – samples from the Gaussian distribution parametrized by
&#64;mu and &#64;logvar. May not be needed depending on the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>KL divergence loss</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.Prior.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.Prior.sample">
<code class="sig-name descname"><span class="pre">sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a batch of samples from the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent. Leading dimension should
be consistent with &#64;n, the number of samples to generate.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of sampled latent vectors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.vae_nets.Prior.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.Prior.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.vae_nets.VAE">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></code><code class="sig-name descname"><span class="pre">VAE</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_reconstruction_sum_across_elements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_squash</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scales</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_ranges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_learn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_gmm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_learn_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_gumbel_softmax_hard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A Variational Autoencoder (VAE), as described in <a class="reference external" href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a>.</p>
<p>Models a distribution p(X) or a conditional distribution p(X | Y), where each
variable can consist of multiple modalities. The target variable X, whose
distribution is modeled, is specified through the &#64;input_shapes argument,
which is a map between modalities (strings) and expected shapes. In this way,
a variable that consists of multiple kinds of data (e.g. image and flat-dimensional)
can be modeled as well. A separate &#64;output_shapes argument is used to specify the
expected reconstructions - this allows for asymmetric reconstruction (for example,
reconstructing low-resolution images).</p>
<p>This implementation supports learning conditional distributions as well (cVAE).
The conditioning variable Y is specified through the &#64;condition_shapes argument,
which is also a map between modalities (strings) and expected shapes. In this way,
variables with multiple kinds of data (e.g. image and flat-dimensional) can
jointly be conditioned on. By default, the decoder takes the conditioning
variable Y as input. To force the decoder to reconstruct from just the latent,
set &#64;decoder_is_conditioned to False (in this case, the prior must be conditioned).</p>
<p>The implementation also supports learning expressive priors instead of using
the usual N(0, 1) prior. There are three kinds of priors supported - Gaussian,
Gaussian Mixture Model (GMM), and Categorical. For each prior, the parameters can
be learned as independent parameters, or be learned as functions of the conditioning
variable Y (by setting &#64;prior_is_conditioned).</p>
<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.decode">
<code class="sig-name descname"><span class="pre">decode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass latents through decoder. Latents should be passed in to
this function at train-time for backpropagation, but they
can be left out at test-time. In this case, latents will
be sampled using the VAE prior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – if provided, these latents are used to generate
reconstructions from the VAE, and the prior is not sampled.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number of samples to
generate from the prior. Only required if &#64;z is None - i.e.
sampling takes place</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary of reconstructed inputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>recons (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.encode">
<code class="sig-name descname"><span class="pre">encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.encode" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – a dictionary that maps input modalities to torch.Tensor
batches. These should correspond to the encoder-only modalities
(i.e. &#64;self.encoder_only_shapes).</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary with posterior parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>posterior params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>A full pass through the VAE network to construct KL and reconstruction
losses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – a dictionary that maps input modalities to torch.Tensor
batches. These should correspond to the encoder-only modalities
(i.e. &#64;self.encoder_only_shapes).</p></li>
<li><p><strong>outputs</strong> (<em>dict</em>) – a dictionary that maps output modalities to torch.Tensor
batches. These should correspond to the modalities used for
reconstruction (i.e. &#64;self.output_shapes).</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
<li><p><strong>freeze_encoder</strong> (<em>bool</em>) – if True, don’t backprop into encoder by detaching
encoder outputs. Useful for doing staged VAE training.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>a dictionary that contains the following outputs.</p>
<blockquote>
<div><dl class="simple">
<dt>encoder_params (dict): parameters for the posterior distribution</dt><dd><p>from the encoder forward pass</p>
</dd>
</dl>
<p>encoder_z (torch.Tensor): latents sampled from the encoder posterior</p>
<p>decoder_outputs (dict): reconstructions from the decoder</p>
<p>kl_loss (torch.Tensor): KL loss over the batch of data</p>
<p>reconstruction_loss (torch.Tensor): reconstruction loss over the batch of data</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>vae_outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.get_gumbel_temperature">
<code class="sig-name descname"><span class="pre">get_gumbel_temperature</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.get_gumbel_temperature" title="Permalink to this definition">¶</a></dt>
<dd><p>Return current Gumbel-Softmax temperature. Should only be used if
&#64;self.prior_use_categorical is True.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.kl_loss">
<code class="sig-name descname"><span class="pre">kl_loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.kl_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes KL divergence loss given the results of the VAE encoder forward
pass and the conditioning and goal modalities (if the prior is input-dependent).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with keys “mu” and “logvar” corresponding
to torch.Tensor batch of means and log-variances of posterior Gaussian
distribution. This is the output of &#64;self.encode.</p></li>
<li><p><strong>encoder_z</strong> (<em>torch.Tensor</em>) – samples from the Gaussian distribution parametrized by
&#64;mu and &#64;logvar. Only required if using a GMM prior.</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – inputs according to &#64;self.condition_shapes. Only needs to be provided
if any prior parameters are input-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;self.goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>VAE KL divergence loss</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.reconstruction_loss">
<code class="sig-name descname"><span class="pre">reconstruction_loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reconstructions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.reconstruction_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Reconstruction loss. Note that we compute the average per-dimension error
in each modality and then average across all the modalities.</p>
<p>The beta term for weighting between reconstruction and kl losses will
need to be tuned in practice for each situation (see
<a class="reference external" href="https://twitter.com/memotv/status/973323454350090240">https://twitter.com/memotv/status/973323454350090240</a> for more
discussion).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reconstructions</strong> (<em>dict</em>) – reconstructed inputs, consistent with
&#64;self.output_shapes</p></li>
<li><p><strong>targets</strong> (<em>dict</em>) – reconstruction targets, consistent with
&#64;self.output_shapes</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>VAE reconstruction loss</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>reconstruction_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.reparameterize">
<code class="sig-name descname"><span class="pre">reparameterize</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.reparameterize" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>posterior</em>) – dictionary from encoder forward pass that
parametrizes the encoder distribution</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>sampled latents that are also differentiable</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.sample_prior">
<code class="sig-name descname"><span class="pre">sample_prior</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.sample_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples from the prior using the prior parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>sampled latents from the prior</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.vae_nets.VAE.set_gumbel_temperature">
<code class="sig-name descname"><span class="pre">set_gumbel_temperature</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">temperature</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.set_gumbel_temperature" title="Permalink to this definition">¶</a></dt>
<dd><p>Used by external algorithms to schedule Gumbel-Softmax temperature,
which is used during reparametrization at train-time. Should only
be used if &#64;self.prior_use_categorical is True.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.vae_nets.VAE.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.VAE.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="robomimic.models.vae_nets.vae_args_from_config">
<code class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></code><code class="sig-name descname"><span class="pre">vae_args_from_config</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vae_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.vae_args_from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of VAE args that are read from the VAE-specific part
of a config (for example see <cite>config.algo.vae</cite> in BCConfig).</p>
</dd></dl>

</div>
<div class="section" id="module-robomimic.models.value_nets">
<span id="robomimic-models-value-nets-module"></span><h2>robomimic.models.value_nets module<a class="headerlink" href="#module-robomimic.models.value_nets" title="Permalink to this headline">¶</a></h2>
<p>Contains torch Modules for value networks. These networks take an
observation dictionary as input (and possibly additional conditioning,
such as subgoal or goal dictionaries) and produce value or
action-value estimates or distributions.</p>
<dl class="py class">
<dt id="robomimic.models.value_nets.ActionValueNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.value_nets.</span></code><code class="sig-name descname"><span class="pre">ActionValueNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ActionValueNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.value_nets.ValueNetwork" title="robomimic.models.value_nets.ValueNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.value_nets.ValueNetwork</span></code></a></p>
<p>A basic Q (action-value) network that predicts values from observations
and actions. Can optionally be goal conditioned on future observations.</p>
<dl class="py method">
<dt id="robomimic.models.value_nets.ActionValueNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ActionValueNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Modify forward from super class to include actions in inputs.</p>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.value_nets.ActionValueNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.value_nets.ActionValueNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.value_nets.DistributionalActionValueNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.value_nets.</span></code><code class="sig-name descname"><span class="pre">DistributionalActionValueNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_atoms</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.value_nets.ActionValueNetwork" title="robomimic.models.value_nets.ActionValueNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.value_nets.ActionValueNetwork</span></code></a></p>
<p>Distributional Q (action-value) network that outputs a categorical distribution over
a discrete grid of value atoms. See <a class="reference external" href="https://arxiv.org/pdf/1707.06887.pdf">https://arxiv.org/pdf/1707.06887.pdf</a> for
more details.</p>
<dl class="py method">
<dt id="robomimic.models.value_nets.DistributionalActionValueNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return mean of critic categorical distribution. Useful for obtaining
point estimates of critic values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>acts</strong> (<em>torch.Tensor</em>) – batch of actions</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>expectation of value distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>mean_value (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.value_nets.DistributionalActionValueNetwork.forward_train">
<code class="sig-name descname"><span class="pre">forward_train</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Return full critic categorical distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>acts</strong> (<em>torch.Tensor</em>) – batch of actions</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>value_distribution (DiscreteValueDistribution instance)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.value_nets.DistributionalActionValueNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="robomimic.models.value_nets.ValueNetwork">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">robomimic.models.value_nets.</span></code><code class="sig-name descname"><span class="pre">ValueNetwork</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visual_core_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_randomizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_spatial_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_softmax_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_nets.MIMO_MLP" title="robomimic.models.obs_nets.MIMO_MLP"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_nets.MIMO_MLP</span></code></a></p>
<p>A basic value network that predicts values from observations.
Can optionally be goal conditioned on future observations.</p>
<dl class="py method">
<dt id="robomimic.models.value_nets.ValueNetwork.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward through value network, and then optionally use tanh scaling.</p>
</dd></dl>

<dl class="py method">
<dt id="robomimic.models.value_nets.ValueNetwork.output_shape">
<code class="sig-name descname"><span class="pre">output_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="robomimic.models.value_nets.ValueNetwork.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-robomimic.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-robomimic.models" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="robomimic.utils.html" class="btn btn-neutral float-right" title="robomimic.utils package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="robomimic.envs.html" class="btn btn-neutral float-left" title="robomimic.envs package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Ajay Mandlekar, Danfei Xu, Josiah Wong, Soroush Nasiriany, Chen Wang.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>